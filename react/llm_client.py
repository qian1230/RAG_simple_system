# llm_client.py
import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class HelloAgentsLLM:
    """
    ä¸º "Hello Agents" å®šåˆ¶çš„LLMå®¢æˆ·ç«¯ï¼Œå…¼å®¹OpenAIæ¥å£ï¼ˆå¦‚ç«å±±æ–¹èˆŸï¼‰
    """
    def __init__(self, model: str = None, api_key: str = None, base_url: str = None, timeout: int = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä».envè¯»å–
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        api_key = api_key or os.getenv("LLM_API_KEY")
        base_url = base_url or os.getenv("LLM_BASE_URL")
        self.timeout = timeout or int(os.getenv("LLM_TIMEOUT", 60))

        # æ ¡éªŒå¿…è¦å‚æ•°
        if not all([self.model, api_key, base_url]):
            raise ValueError("æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»åœ¨.envä¸­é…ç½®ï¼")

        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url,
            timeout=self.timeout
        )

    def think(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        """
        è°ƒç”¨LLMç”Ÿæˆå“åº”ï¼ˆæµå¼è¾“å‡ºï¼‰
        :param messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼[{"role": "user/system", "content": "å†…å®¹"}]
        :param temperature: ç”Ÿæˆæ¸©åº¦ï¼Œ0-1ä¹‹é—´
        :return: å®Œæ•´å“åº”æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
                max_tokens=2048
            )

            # å¤„ç†æµå¼å“åº”
            print("âœ… LLMå“åº”ä¸­:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end="", flush=True)
                collected_content.append(content)

            print()  # æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
            return "".join(collected_content)

        except Exception as e:
            print(f"\nâŒ LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return None

# æµ‹è¯•ä»£ç ï¼ˆå¯é€‰ï¼‰
if __name__ == '__main__':
    try:
        llm = HelloAgentsLLM()
        test_msg = [{"role": "user", "content": "ä½ å¥½ï¼Œæµ‹è¯•ä¸€ä¸‹ï¼"}]
        llm.think(test_msg)
    except ValueError as e:
        print(e)